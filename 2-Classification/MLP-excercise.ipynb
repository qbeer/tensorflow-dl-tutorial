{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Multilayer Perceptron\n",
    "\n",
    "[Similar tutorial](https://www.tensorflow.org/get_started/mnist/pros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "cXBoqDwV2z3V"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "biXxnT2wRQpo"
   },
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST dataset can be automatically downloaded via tensorflow with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 85,
     "output_extras": [
      {
       "item_id": 2
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 947,
     "status": "ok",
     "timestamp": 1510073056333,
     "user": {
      "displayName": "David Nagy",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "116820342271745675144"
     },
     "user_tz": -60
    },
    "id": "-R0HUxwNHvI6",
    "outputId": "56b00892-486c-4759-d82c-6ef8003164a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try plotting one of the datapoints (from mnist.train.images) with matplotlib's `plt.imshow`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fcf944db518>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAADq5JREFUeJzt3X+QVfV5x/HPw7Igv6xsEULIRqJiWsfOoN1AJiQpGaoFawZMRwuTEppmxEwlldHM1KEzCdOZtI6NpjRGnIXQYAdNMk0UptI0htQY24osVAUlKHWorOwAFiKghh/L0z/2kFlxz3d37z33ngvP+zXj3HvPc849j1c/e+6933PP19xdAOIZUnYDAMpB+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBDW0njsbZsP9Ao2q5y6BUH6lt3TCj9tA1q0q/GY2W9IKSU2SVrv73an1L9AoTbdZ1ewSQMJm3zTgdSt+229mTZK+JWmOpCslLTCzKyt9PgD1Vc1n/mmSdrv7q+5+QtJ3Jc0tpi0AtVZN+CdJ2tvrcWe27F3MbLGZdZhZx0kdr2J3AIpUTfj7+lLhPb8Pdvd2d29z97ZmDa9idwCKVE34OyW19nr8AUn7qmsHQL1UE/4tkqaY2YfMbJik+ZI2FNMWgFqreKjP3U+Z2RJJ/6aeob417v5iYZ0BqKmqxvndfaOkjQX1AqCOOL0XCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoKqapdfM9kg6Kqlb0il3byuiKbxb08UXJ+unLn9/bu21OSOT256YfDxZX3LNk8n67WN3J+tNln986fbTyW3XHR2frL/ZPSpZv3FM/ozxn/jJ0uS2V/xZR7J+Pqgq/JlPufsbBTwPgDribT8QVLXhd0k/NrOtZra4iIYA1Ee1b/tnuPs+Mxsv6Qkz+4W7P9V7heyPwmJJukDpz58A6qeqI7+778tuD0h6VNK0PtZpd/c2d29r1vBqdgegQBWH38xGmdmYM/clXSdpR1GNAaitat72T5D0qJmdeZ6H3f1HhXQFoObM3eu2swutxafbrLrtr16Oz/lIsn60Nf039le/acn6LX+yMVm/7aL/ya09ezz93Etfmp+sv/XMuGR93I5TyXo1Rj+5K1nv/uWbyfpryz+WW1v9ufuT2/71pdck641qs2/SET+U/o+eYagPCIrwA0ERfiAowg8ERfiBoAg/EBRDfQU4/PiUZH397/xjun7sw8n63/3o08n6xVvzay0/eTW5bff+A8n6uaz5yYm5tZPdTemNZ3UW3E19MNQHoF+EHwiK8ANBEX4gKMIPBEX4gaAIPxBUEVfvDW/k/Rcl6wvf+YtkvenJbcn65Xpm0D2d0V3xlo1v930fTdbXffBbubVbVn4pue37dW6O8w8GR34gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIpx/gIM/9ctZbdwXvIZU5P1l//4gWT9n47m/56/dfXO5Lbn8/kRZ3DkB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGg+h3nN7M1km6QdMDdr8qWtUj6nqTJkvZIutndD9euTZyPTsxOT22+4sFvJut//vqnkvW9n80f5+8+nJ7PIIKBHPm/I2n2WcvukrTJ3adI2pQ9BnAO6Tf87v6UpENnLZ4raW12f62keQX3BaDGKv3MP8HduyQpux1fXEsA6qHm5/ab2WJJiyXpAo2s9e4ADFClR/79ZjZRkrLb3Nke3b3d3dvcva1ZwyvcHYCiVRr+DZIWZfcXSVpfTDsA6qXf8JvZI5L+S9KHzazTzL4g6W5J15rZK5KuzR4DOIf0+5nf3RfklGYV3AvOQ113fCy31r4kPY6/bM+NyfrJmV397J2x/BTO8AOCIvxAUIQfCIrwA0ERfiAowg8ExaW7kWTNw5L1Xf+Qvrz2T6+/J7f2xd3z0/uenXviKArAkR8IivADQRF+ICjCDwRF+IGgCD8QFOEHgmKcP7imKZcm68NWv5Wsv3z5ymT96s235tYmfebF5LaerKJaHPmBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjG+c8DXXfmXx772OTu5Larrl+drM8akd7+ZD+D8aunPpRbW7Dqi8ltW//FkvUR659N7xxJHPmBoAg/EBThB4Ii/EBQhB8IivADQRF+IKh+x/nNbI2kGyQdcPersmXLJd0i6WC22jJ331irJs93f7DjSLJ++9jd/TzDttxKV/fbyS3/+ehVyfqX770+WR//wH8m6ylj7mxO1tff//Vk/SOfuCNZv+zLzwy6p0gGcuT/jqTZfSz/hrtPzf4h+MA5pt/wu/tTkg7VoRcAdVTNZ/4lZvaCma0xs7GFdQSgLioN/0pJl0maKqlL0r15K5rZYjPrMLOOkzpe4e4AFK2i8Lv7fnfvdvfTklZJmpZYt93d29y9rVnDK+0TQMEqCr+ZTez18EZJO4ppB0C9DGSo7xFJMyWNM7NOSV+VNNPMpqrn6sp7JOVfnxlAQzL3+l0d/UJr8ek2q277O1ccfnxKsu6e/l370HUtubXRnenvWYb8/L+T9TJ13ZF/nQJJ2rj0nmT98wu/lFsb8rPG/feuxmbfpCN+KP0/TIYz/ICgCD8QFOEHgiL8QFCEHwiK8ANBcenuBjD2D18pu4WGNGnV9mS9c8mIZL35jfyfM6cvSB4DR34gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIpxfjSsXX9zZbL+zDt7k/XuF3cV2c55hyM/EBThB4Ii/EBQhB8IivADQRF+ICjCDwTFOD9Kc/K6tmT92Xn3Jetznv98st6ilwfdUyQc+YGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gqH7H+c2sVdJDkt4n6bSkdndfYWYtkr4nabKkPZJudvfDtWu1XO/Mm5ZbG/HYs3Xs5Nwy9JLW3NqIv0r/Hn9fd1Oy3nID4/jVGMiR/5SkO939tyV9VNJtZnalpLskbXL3KZI2ZY8BnCP6Db+7d7n7tuz+UUk7JU2SNFfS2my1tZLm1apJAMUb1Gd+M5ss6WpJmyVNcPcuqecPhKTxRTcHoHYGHH4zGy3pB5KWuvuRQWy32Mw6zKzjpI5X0iOAGhhQ+M2sWT3BX+fuP8wW7zeziVl9oqQDfW3r7u3u3ububc0aXkTPAArQb/jNzCR9W9JOd+/9M6sNkhZl9xdJWl98ewBqZSA/6Z0haaGk7Wb2XLZsmaS7JX3fzL4g6TVJN9Wmxfp4+zPTk/WD8/One77ksaK7OX/sXTE6t7aydV1y26WLlyTrzeqoqCf06Df87v60JMspzyq2HQD1whl+QFCEHwiK8ANBEX4gKMIPBEX4gaDM3eu2swutxadbY44ODhk5Mlm/9fkXcmsP7v299HPf9E6y3v1/h5L1WhoyZky63nJRsv7SXROT9Suu2JdbO/W1Cclth/50a7KO99rsm3TED+UNzb8LR34gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIopujOn387/vb4kPfC5P8qtHf3KseS2t/7HlmT9wVc/mawffzx9ecTR+7pza6//fnJTLfz408n6V8b9LFmf8fzNyfqQT+efwzD07c7ktqgtjvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBS/5y9A00W/kax3/9YlyfrBZelpzDb/7sOD7mmgpnV8Nlkf/7fDkvWmX/xvst79yzcH3RMqx+/5AfSL8ANBEX4gKMIPBEX4gaAIPxAU4QeC6nec38xaJT0k6X2STktqd/cVZrZc0i2SDmarLnP3jannOl/H+YFGMZhx/oFczOOUpDvdfZuZjZG01cyeyGrfcPevV9oogPL0G35375LUld0/amY7JU2qdWMAamtQn/nNbLKkqyVtzhYtMbMXzGyNmY3N2WaxmXWYWcdJpU9jBVA/Aw6/mY2W9ANJS939iKSVki6TNFU97wzu7Ws7d2939zZ3b2vW8AJaBlCEAYXfzJrVE/x17v5DSXL3/e7e7e6nJa2SNK12bQIoWr/hNzOT9G1JO939vl7Le0/PeqOkHcW3B6BWBvJt/wxJCyVtN7PnsmXLJC0ws6mSXNIeSbfWpEMANTGQb/ufltTXuGFyTB9AY+MMPyAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFB1naLbzA5K6j2n8zhJb9StgcFp1N4atS+J3ipVZG+XuPvFA1mxruF/z87NOty9rbQGEhq1t0btS6K3SpXVG2/7gaAIPxBU2eFvL3n/KY3aW6P2JdFbpUrprdTP/ADKU/aRH0BJSgm/mc02s11mttvM7iqjhzxmtsfMtpvZc2bWUXIva8zsgJnt6LWsxcyeMLNXsts+p0krqbflZvZ69to9Z2bXl9Rbq5n9u5ntNLMXzez2bHmpr12ir1Jet7q/7TezJkkvS7pWUqekLZIWuPtLdW0kh5ntkdTm7qWPCZvZJyUdk/SQu1+VLbtH0iF3vzv7wznW3f+yQXpbLulY2TM3ZxPKTOw9s7SkeZL+VCW+dom+blYJr1sZR/5pkna7+6vufkLSdyXNLaGPhufuT0k6dNbiuZLWZvfXqud/nrrL6a0huHuXu2/L7h+VdGZm6VJfu0RfpSgj/JMk7e31uFONNeW3S/qxmW01s8VlN9OHCdm06WemTx9fcj9n63fm5no6a2bphnntKpnxumhlhL+v2X8aachhhrtfI2mOpNuyt7cYmAHN3Fwvfcws3RAqnfG6aGWEv1NSa6/HH5C0r4Q++uTu+7LbA5IeVePNPrz/zCSp2e2Bkvv5tUaaubmvmaXVAK9dI814XUb4t0iaYmYfMrNhkuZL2lBCH+9hZqOyL2JkZqMkXafGm314g6RF2f1FktaX2Mu7NMrMzXkzS6vk167RZrwu5SSfbCjj7yU1SVrj7l+rexN9MLNL1XO0l3omMX24zN7M7BFJM9Xzq6/9kr4q6TFJ35f0QUmvSbrJ3ev+xVtObzPV89b11zM3n/mMXefePi7p55K2SzqdLV6mns/Xpb12ib4WqITXjTP8gKA4ww8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFD/D+B4LhTMCPHiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist.train.images[2132].reshape(28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pG9Gd1JIRf0z"
   },
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define placeholders for the data and labels, however now instead of feeding in one datapoint at a time, define the placeholders for minibatches of size 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "\n",
    "batch = tf.placeholder(dtype=tf.float32, shape=(None, 784))\n",
    "batch_label = tf.placeholder(dtype=tf.float32, shape=(None, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now define a two-layer perceptron with a third output layer, where each layer is a linear transformation followed by a sigmoid nonlinearity:\n",
    "\n",
    "$$y=\\sigma_{softmax}\\circ A_2 \\circ \\sigma \\circ A_1\\circ \\mathbf{W} $$\n",
    "\n",
    "where \n",
    "- $A_i(x)=\\mathbf{W}_i \\mathbf{x}+\\mathbf{b}_i$,\n",
    "- $\\sigma$ is a [sigmoid](https://en.wikipedia.org/wiki/Sigmoid_function) function (`tf.nn.sigmoid`) and\n",
    "- $\\sigma_{softmax}$ is a [softmax](https://en.wikipedia.org/wiki/Softmax_function) function (`tf.nn.softmax`).\n",
    "\n",
    "As initial values for the parameters, use a truncated normal with `stddev = 0.1` for the weight and a constant `0.1` for the bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.random_normal(shape=(784, 42), stddev=0.1))\n",
    "b1 = tf.Variable(tf.ones(shape=(1, 42))/10.)\n",
    "\n",
    "z = tf.nn.sigmoid(tf.matmul(batch, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal(shape=(42, 10), stddev=0.1))\n",
    "b2 = tf.Variable(tf.ones(shape=(1, 10))/10.)\n",
    "\n",
    "output = tf.nn.softmax(tf.matmul(z, W2) + b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8k9dah0HRh08"
   },
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a cross-entropy loss function \n",
    "$$-\\sum y_{true} \\cdot \\log y$$\n",
    "and an optimizer. The loss should be minimised on average over the minibatch. Try both the gradient descent optimizer from the previous excercise and the [Adam](https://arxiv.org/abs/1412.6980) optimizer. There is [possible numerical instability](https://deepnotes.io/softmax-crossentropy) of the loss function if it is defined directly with the above equation, which can be cirumvented for example by using the built-in `tf.nn.softmax_cross_entropy_with_logits` in the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(-tf.reduce_sum(batch_label * tf.log(output)))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DWhv9Tj0RjNJ"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, write a training loop where you initialize the variables and iterate over minibatches of data. You can get the next minibatch of size N with:\n",
    "```\n",
    "x_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "```\n",
    "Print out the loss, train and test errors at every n-th step, either to stdout or to tensorboard. As a guide, test accuracy of at least 97% is possible with this setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc: 0.0958\n",
      "train acc: 0.09849091\n",
      "test acc: 0.856\n",
      "train acc: 0.84694546\n",
      "test acc: 0.8938\n",
      "train acc: 0.88994545\n",
      "test acc: 0.9075\n",
      "train acc: 0.9050364\n",
      "test acc: 0.9156\n",
      "train acc: 0.9150182\n",
      "test acc: 0.9213\n",
      "train acc: 0.92047274\n",
      "test acc: 0.928\n",
      "train acc: 0.92667276\n",
      "test acc: 0.9309\n",
      "train acc: 0.93085456\n",
      "test acc: 0.9332\n",
      "train acc: 0.9354727\n",
      "test acc: 0.9361\n",
      "train acc: 0.9398909\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(2000):\n",
    "        x_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "        loss_, _ = sess.run((loss, optimizer), feed_dict={batch: x_batch, batch_label: y_batch })\n",
    "        if (i % 200 == 0):\n",
    "            correct = tf.equal(tf.argmax(output,1), tf.argmax(batch_label,1))\n",
    "            print(\"test acc:\", sess.run(tf.reduce_mean(tf.cast(correct, tf.float32)),\n",
    "                           feed_dict={batch: mnist.test.images, batch_label: mnist.test.labels}))\n",
    "            print(\"train acc:\", sess.run(tf.reduce_mean(tf.cast(correct, tf.float32)),\n",
    "                           feed_dict={batch: mnist.train.images, batch_label: mnist.train.labels}))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "Multilayer perceptron.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "nteract": {
   "version": "0.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
