{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Multilayer Perceptron\n",
    "\n",
    "[Similar tutorial](https://www.tensorflow.org/get_started/mnist/pros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "cXBoqDwV2z3V"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "biXxnT2wRQpo"
   },
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST dataset can be automatically downloaded via tensorflow with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 85,
     "output_extras": [
      {
       "item_id": 2
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 947,
     "status": "ok",
     "timestamp": 1510073056333,
     "user": {
      "displayName": "David Nagy",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "116820342271745675144"
     },
     "user_tz": -60
    },
    "id": "-R0HUxwNHvI6",
    "outputId": "56b00892-486c-4759-d82c-6ef8003164a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try plotting one of the datapoints (from mnist.train.images) with matplotlib's `plt.imshow`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 784 into shape (64,64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f85e9982cff2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 784 into shape (64,64)"
     ]
    }
   ],
   "source": [
    "mnist.train.images[0].reshape(28, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pG9Gd1JIRf0z"
   },
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define placeholders for the data and labels, however now instead of feeding in one datapoint at a time, define the placeholders for minibatches of size 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now define a two-layer perceptron with a third output layer, where each layer is a linear transformation followed by a sigmoid nonlinearity:\n",
    "\n",
    "$$y=\\sigma_{softmax}\\circ A_2 \\circ \\sigma \\circ A_1\\circ \\mathbf{W} $$\n",
    "\n",
    "where \n",
    "- $A_i(x)=\\mathbf{W}_i \\mathbf{x}+\\mathbf{b}_i$,\n",
    "- $\\sigma$ is a [sigmoid](https://en.wikipedia.org/wiki/Sigmoid_function) function (`tf.nn.sigmoid`) and\n",
    "- $\\sigma_{softmax}$ is a [softmax](https://en.wikipedia.org/wiki/Softmax_function) function (`tf.nn.softmax`).\n",
    "\n",
    "As initial values for the parameters, use a truncated normal with `stddev = 0.1` for the weight and a constant `0.1` for the bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8k9dah0HRh08"
   },
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a cross-entropy loss function \n",
    "$$-\\sum y_{true} \\cdot \\log y$$\n",
    "and an optimizer. The loss should be minimised on average over the minibatch. Try both the gradient descent optimizer from the previous excercise and the [Adam](https://arxiv.org/abs/1412.6980) optimizer. There is [possible numerical instability](https://deepnotes.io/softmax-crossentropy) of the loss function if it is defined directly with the above equation, which can be cirumvented for example by using the built-in `tf.nn.softmax_cross_entropy_with_logits` in the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DWhv9Tj0RjNJ"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, write a training loop where you initialize the variables and iterate over minibatches of data. You can get the next minibatch of size N with:\n",
    "```\n",
    "x_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "```\n",
    "Print out the loss, train and test errors at every n-th step, either to stdout or to tensorboard. As a guide, test accuracy of at least 97% is possible with this setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "Multilayer perceptron.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "nteract": {
   "version": "0.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
